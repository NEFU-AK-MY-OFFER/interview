# 进程

## 问题

### 基本概念

* 什么是进程？进程与程序的区别？
* 什么是控制终端、进程组、会话？它们之间是什么关系
* 什么是孤儿进程？什么是僵尸进程？有哪些危害？如何避免僵尸进程？
* 终端退出，终端运行的进程会怎样？
* 如何让进程后台运行？
* 什么是守护进程？如何创建守护进程？（手搓）
* 怎么知道一个进程死亡？怎么 hook 一个进程的准确死亡时间？

### 进程通信

* 进程间通信方式？
* 管道怎么实现的？
* 共享内存原理
* 共享内存和内存映射的区别
* 共享内存通过什么来管理，有那些 API？

### 进程调度

* 进程状态及其转换？

* 什么时候发生调度？

* 不能进行调度的情况？

* 非抢占式调度和抢占式调度区别？

* 调度算法考虑哪些原则？

* 单核 CPU 常见进程调度算法有哪些？特点、优缺点、适用情况？

* 谈谈比例份额调度？
  * 彩票机制
  * 步长调度
  * 谈谈Linux完全公平调度？
  
* 谈谈多级反馈队列？
  * 没有工作长度的先验知识，如何减少响应时间和周转时间？
  * 如何设置优先级的？
  * 多级反馈队列如何配置或调优？
  
* 多处理器调度？

* 时间片调度的时间片如何校准时间？

* 谈谈优先级反转以及解决思路？

* Linux 如何调度线程？（CPU 如何选择线程）

  * 调度类
  * 完全公平调度
  * CPU 运行队列
  * 调整优先级

### 进程上下文切换

* 谈一下系统调用、CPU 上下文切换、进程上下文切换、线程上下文切换、中断上下文切换？
* 进程在哪些场景会进行上下文切换？
* 进程上下文切换做了哪些事？流程是怎么样的？
* 上下文切换为什么资源消耗会比较高？消耗在什么地方？

### 进程控制

* 进程控制结构，包含哪些信息？
* PCB 是如何组织？几种方式优缺点（要改）
* 如何创建进程？
* 如何终止进程？
* 如何阻塞进程？
* 如何唤醒进程？
* Linux 系统如何管理进程？
* fork 和 vfork 区别
* fork,wait,exec
* fork复制内部，为什么fork返回0？

## 回答

## 基本概念

#### 什么是进程？进程与程序的区别？

我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，**那么这个运行中的程序，就被称为「进程」（Process）**

* 程序是指令和数据的有序集合，是一个静态的概念。而进程是程序在处理机上的一次执行过程，它是一个 动态的概念。
* 程序可以作为一种软件资料长期存在，而进程是有一定生命期的。程序是永久的，进程是暂时的。
* 进程是由进程控制块、程序段、数据段三部分组成;
* 进程具有创建其他进程的功能，而程序没有。
* 同一程序同时运行于若干个数据集合上，它将属于若干个不同的进程，也就是说同一程序可以对应多个进 程。
* 在传统的操作系统中，程序并不能独立运行，作为资源分配和独立运行的基本单元都是进程。

进程是操作系统中最重要的抽象概念之一，是资源分配的基本单位，是独立运行的基本单位。

进程的经典定义就是一个执行中程序的实例。系统中的每个程序都运行在某个进程的上下文（context）中。

上下文是由程序正确运行所需的状态组成的。**这个状态包括存放在内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合**。

进程一般由以下的部分组成：

1. 进程控制块PCB，是进程存在的唯一标志，包含进程标识符PID，进程当前状态，程序和数据地
 址，进程优先级、CPU现场保护区（用于进程切换），占有的资源清单等。
2. 程序段
3. 数据段

#### 什么是控制终端、进程组、会话？它们之间是什么关系

**终端**

* 在 UNIX 系统中，用户通过终端登录系统后得到一个 shell 进程，这个终端成为 shell 进程的控制终端（Controlling Terminal），进程中，控制终端是保存在 PCB 中的信息，而 fork() 会复制 PCB 中的信息，因此由 shell 进程启动的其它进程的控制终端也是这个终端。
* 默认情况下（没有重定向），每个进程的标准输入、标准输出和标准错误输出都指向控制终端，进程从标准输入读也就是读用户的键盘输入，进程往标准输出或标准错误输出写也就是输出到显示器上。
* 在控制终端输入一些特殊的控制键可以给前台进程发信号，例如 Ctrl + C 会产生 SIGINT 信号，Ctrl + \ 会产生 SIGQUIT 信号。

**进程组**

每个进程都属于一个进程组。每个进程组都有一个组长进程，组长进程的进程号等于进程组 ID。只要某个进程组中有一个进程存在，则该进程组就存在，与组长进程是否终止无关。从进程组创建开始到其中最后一个进程离开为止的时间区间成为进程组的生存期。进程组中最后一个进程可以终止或者转移到另一个进程组中。

* 进程组和会话在进程之间形成了一种两级层次关系：进程组是一组相关进程的集合，会话是一组相关进程组的集合。进程组和会话是为支持 shell 作业控制而定义的抽象概念，用户通过 shell 能够交互式地在前台或后台运行命令。
* 进行组由一个或多个共享同一进程组标识符（PGID）的进程组成。一个进程组拥有一个进程组首进程，该进程是创建该组的进程，其进程 ID 为该进程组的 ID，新进程会继承其父进程所属的进程组 ID。
* 进程组拥有一个生命周期，其开始时间为首进程创建组的时刻，结束时间为最后一个成员进程退出组的时刻。一个进程可能会因为终止而退出进程组，也可能会因为加入了另外一个进程组而退出进程组。进程组首进程无需是最后一个离开进程组的成员。

**会话**

* 会话是一组进程组的集合。会话首进程是创建该新会话的进程，其进程 ID 会成为会话 ID。新进程会继承其父进程的会话 ID。
* 一个会话中的所有进程共享单个控制终端。控制终端会在会话首进程首次打开一个终端设备时被建立。一个终端最多可能会成为一个会话的控制终端
* 在任一时刻，会话中的其中一个进程组会成为终端的前台进程组，其他进程组会成为后台进程组。只有前台进程组中的进程才能从控制终端中读取输入。当用户在控制终
 端中输入终端字符生成信号后，该信号会被发送到前台进程组中的所有成员。

* 当控制终端的连接建立起来之后，会话首进程会成为该终端的控制进程

![在这里插入图片描述](https://img-blog.csdnimg.cn/8b9b94fd6e7b45399e962e60efb2d81f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6bG856u_6ZKT6bG85bmy,size_20,color_FFFFFF,t_70,g_se,x_16)

#### 什么是孤儿进程？什么是僵尸进程？有哪些危害？如何避免？

**unix提供了一种机制保证父进程知道子进程结束时的状态信息。**

这种机制是：在每个进程退出的时候，内核会释放所有的资源，包括打开的文件，占用的内存等。但是仍保留一部分信息(进程号 PID，退出状态，运行时间等)。直到父进程通过 wait 或 waitpid 来取时才释放。

但是这样就会产生问题：如果父进程不调用wait或waitpid的话，那么保留的信息就不会被释放，其进程号就会被一直占用，**但是系统所能使用的进程号是有限的，如果大量产生僵死进程，将因没有可用的进程号而导致系统无法产生新的进程，这就是僵尸进程的危害**

孤儿进程是没有父进程的进程，它由init进程循环的wait()回收资源，init进程充当父进程。因此**孤儿进程并没有什么危害。**

补充：任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程的数据结构，等待父进程去处理。**如果父进程在子进程exit()之后，没有及时处理，出现僵尸进程，并可以用ps命令去查看，它的状态是“Z”。**

**孤儿进程：**父进程结束了，而它的一个或多个子进程还在运行，那么这些子进程就成为孤儿进程(father died)。子进程的资源由init进程(进程号PID = 1)回收。

**僵尸进程：**子进程退出了，但是父进程没有用wait或waitpid去获取子进程的状态信息，那么子进程的进程描述符(包括进程号 PID，退出状态 the termination status of the process，运行时间 the amount of CPU time taken by the process 等)仍然保存在系统中，这种进程称为僵尸进程

**解决方案**

1. kill杀死元凶父进程(一般不用)
 严格的说，僵尸进程并不是问题的根源，罪魁祸首是产生大量僵死进程的父进程。因此，我们可以直接除掉元凶，通过kill发送SIGTERM或者SIGKILL信号。元凶死后，僵尸进程进程变成孤儿进程，由init充当父进程，并回收资源。

 或者运行：kill -9 父进程的pid值、（僵尸进程无法用kill直接杀死）

2. 父进程用wait或waitpid去回收资源(方案不好)
 父进程通过wait或waitpid等函数去等待子进程结束，但是不好，会导致父进程一直等待被挂起，相当于一个进程在干活，没有起到多进程的作用。

3. 通过信号机制，在处理函数中调用wait，回收资源
 通过信号机制，子进程退出时向父进程发送SIGCHLD信号，父进程调用signal(SIGCHLD,sig_child)去处理SIGCHLD信号，在信号处理函数sig_child()中调用wait进行处理僵尸进程。什么时候得到子进程信号，什么时候进行信号处理，父进程可以继续干其他活，不用去阻塞等待。

#### 终端退出，终端运行的进程会怎样？

终端在退出时会发送SIGHUP给对应的bash进程，bash进程收到这个信号后首先将它发给session下面的进 程，如果程序没有对SIGHUP信号做特殊处理，那么进程就会随着终端关闭而退出

#### 如何让进程后台运行？

我们知道，当用户注销（logout）或者网络断开时，终端会收到 HUP（hangup）信号从而关闭其所有子进程。因此，我们的解决办法就有两种途径：要么让进程忽略 HUP 信号，要么让进程运行在新的会话里从而成为不属于此终端的子进程。

**1. nohup**

nohup 无疑是我们首先想到的办法。顾名思义，nohup 的用途就是让提交的命令忽略 hangup 信号。

nohup 的使用是十分方便的，只需在要处理的命令前加上 nohup 即可，标准输出和标准错误缺省会被重定向到 nohup.out 文件中。一般我们可在结尾加上"&"来将命令同时放入后台运行，也可用">filename 2>&1"来更改缺省的重定向文件名。

1. 安装命令（默认没有，可在usr/bin下查看是否安装成功）：

 ```java
 yum install coreutils
 1
 ```

2. 使用示例：

 ```bash
 [root@pythontab ~]# nohup ping www.baidu.com &
 [1] 3059
 nohup: appending output to `nohup.out'
 [root@pythontab ~]# ps -ef |grep 3059
 root      3059   984  0 15:06 pts/3    00:00:00 ping www.baidu.com
 root      3067   984  0 15:06 pts/3    00:00:00 grep 3059
 [root@pythontab ~]#
 1234567
 ```

**2. setsid**

nohup 无疑能通过忽略 HUP 信号来使我们的进程避免中途被中断，但如果我们换个角度思考，如果我们的进程不属于接受 HUP 信号的终端的子进程，那么自然也就不会受到 HUP 信号的影响了。setsid 就能帮助我们做到这一点。

setsid 的使用也是非常方便的，也只需在要处理的命令前加上 setsid 即可。

```bash
[root@pythontab ~]# setsid ping www.baidu.com
[root@pythontab ~]# ps -ef |grep www.baidu.com
root     31094     1  0 07:28 ?        00:00:00 ping www.baidu.com
root     31102 29217  0 07:29 pts/4    00:00:00 grep www.baidu.com
[root@pythontab ~]#
12345
```

值得注意的是，上例中我们的进程 ID(PID)为31094，**而它的父 ID（PPID）为1（即为 init 进程 ID），并不是当前终端的进程 ID。**

**3. screen**

我们已经知道了如何让进程免受 HUP 信号的影响，**但是如果有大量这种命令需要在稳定的后台里运行，如何避免对每条命令都做这样的操作呢？**

此时最方便的方法就是 screen 了。简单的说，screen 提供了 ANSI/VT100 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen 的参数很多，具有很强大的功能，我们在此仅介绍其常用功能以及简要分析一下为什么使用 screen 能够避免 HUP 信号的影响。

使用 screen 很方便，有以下几个常用选项：

* 用screen -dmS session name来建立一个处于断开模式下的会话（并指定其会话名）。
* 用screen -list 来列出所有会话。
* 用screen -r session name来重新连接指定会话。
* 用快捷键CTRL-a d 来暂时断开当前会话。

screen 示例

```
[root@pvcent107 ~]# screen -dmS Urumchi
 
[root@pvcent107 ~]# screen -list
 
There is a screen on:
 
       12842.Urumchi   (Detached)
 
1 Socket in /tmp/screens/S-root.
 
  
 
[root@pvcent107 ~]# screen -r Urumchi
```

当我们用“-r”连接到 screen 会话后，我们就可以在这个伪终端里面为所欲为，再也不用担心 HUP 信号会对我们的进程造成影响，也不用给每个命令前都加上“nohup”或者“setsid”了。这是为什么呢？让我来看一下下面两个例子吧。

1. 未使用 screen 时新进程的进程树

```
[root@pvcent107 ~]# ping www.google.com &
 
[1] 9499
 
[root@pvcent107 ~]# pstree -H 9499
 
init─┬─Xvnc
 
    ├─acpid
 
    ├─atd
 
    ├─2*[sendmail]
 
    ├─sshd─┬─sshd───bash───pstree
 
    │       └─sshd───bash───ping

```

我们可以看出，未使用 screen 时我们所处的 bash 是 sshd 的子进程，当 ssh 断开连接时，HUP 信号自然会影响到它下面的所有子进程（包括我们新建立的 ping 进程）。

2. 使用了 screen 后新进程的进程树

```
[root@pvcent107 ~]# screen -r Urumchi
 
[root@pvcent107 ~]# ping www.ibm.com &
 
[1] 9488
 
[root@pvcent107 ~]# pstree -H 9488
 
init─┬─Xvnc
 
    ├─acpid
 
    ├─atd
 
    ├─screen───bash───ping
 
    ├─2*[sendmail]
```

而使用了 screen 后就不同了，此时 bash 是 screen 的子进程，而 screen 是 init（PID为1）的子进程。那么当 ssh 断开连接时，HUP 信号自然不会影响到 screen 下面的子进程了。

**4. Ctrl + Z 挂起进程，然后 jobs 查看序号，再使用 bg 后台运行进程**

其他

![img](https://img2020.cnblogs.com/blog/1657559/202108/1657559-20210813165932130-69616738.png)

#### 什么是守护进程？如何创建守护进程？（手搓）

守护进程，也就是通常说的Daemon进程，是Linux中的后台服务进程。它是一个生存期较长的进程，通常独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。守护进程是脱离于终端并且在后台运行的进程。守护进程脱离于终端是为了避免进程在执行过程中的信息在任何终端上显示并且进程也不会被任何终端所产生的终端信息所打断。

1. **执行一个 fork()，之后父进程退出，子进程继续执行。**

 守护进程变成孤儿进程，这样就被init进程领养，init进程成为其父进程。由于子进程会继承父进程的会话，进程组，控制终端，文件描述符等，我们要让子进程和原来的这些信息脱离。

2. **子进程调用 setsid() 开启一个新会话。**

 脱离了原来会话组、进程组、控制终端，成为新的会话组组长。（新的会话是没有控制终端的）

 第一步创建子进程的原因是： 当进程是会话组长时setsid()调用失败，两个会话里会产生同样的ID,造成冲突。

 但第一点已经保证进程不是会话组长。setsid()调用成功后，进程成为新的会话组长和新的进程组长，并与原来的登录会话和进程组脱离。由于会话过程对控制终端的独占性，进程同时与控制终端脱离。

3. **清除进程的 umask 以确保当守护进程创建文件和目录时拥有所需的权限**

 设置文件掩码是为了不受父进程的 umask 的影响，能自由创建读写文件和目录

4. **修改进程的当前工作目录，通常会改为根目录（/）。**

 刚启动守护进程的时候默认使用当前位置作为工作目录，如果你用U盘之类的启动就很不合理了。

5. **关闭守护进程从其父进程继承而来的所有打开着的文件描述符。**

 子进程会从父进程继承文件描述符，这些文件描述符会占用资源，因此我们最好关闭它们。至少要关闭 0,1,2 这三个文件描述符，分别对应了 stdin, stdout, 和 stderr。不过通常用 sysconf(_SC_OPEN_MAX) 获取系统允许的最大文件描述符个数，然后全部 close 掉。

6. **在关闭了文件描述符0、1、2之后，守护进程通常会打开/dev/null 并使用dup2() 使所有这些描述符指向这个设备。**

 同时为了防止有些操作使用0,1,2文件描述符出问题，所以重定向到/dev/null设备

 tip：/dev/null设备会把操作给丢弃到

7. **核心业务逻辑**

```c++
/*
    写一个守护进程，每隔2s获取一下系统时间，将这个时间写入到磁盘文件中。
*/

#include <stdio.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/time.h>
#include <signal.h>
#include <time.h>
#include <stdlib.h>
#include <string.h>

void work(int num) {
    // 捕捉到信号之后，获取系统时间，写入磁盘文件
    time_t tm = time(NULL);
    struct tm * loc = localtime(&tm);
    // char buf[1024];

    // sprintf(buf, "%d-%d-%d %d:%d:%d\n",loc->tm_year,loc->tm_mon
    // ,loc->tm_mday, loc->tm_hour, loc->tm_min, loc->tm_sec);

    // printf("%s\n", buf);

    char * str = asctime(loc);
    int fd = open("time.txt", O_RDWR | O_CREAT | O_APPEND, 0664);
    write(fd ,str, strlen(str));
    close(fd);
}

int main() {

    // 1.创建子进程，退出父进程
    pid_t pid = fork();

    if(pid > 0) {
        exit(0);
    }

    // 2.将子进程重新创建一个会话
    setsid();

    // 3.设置掩码
    umask(022);

    // 4.更改工作目录
    chdir("/home/nowcoder/");

    // 5. 关闭、重定向文件描述符
    int fd = open("/dev/null", O_RDWR);
    dup2(fd, STDIN_FILENO);
    dup2(fd, STDOUT_FILENO);
    dup2(fd, STDERR_FILENO);

    // 6.业务逻辑

    // 捕捉定时信号
    struct sigaction act;
    act.sa_flags = 0;
    act.sa_handler = work;
    sigemptyset(&act.sa_mask);
    sigaction(SIGALRM, &act, NULL);

    struct itimerval val;
    val.it_value.tv_sec = 2;
    val.it_value.tv_usec = 0;
    val.it_interval.tv_sec = 2;
    val.it_interval.tv_usec = 0;

    // 创建定时器
    setitimer(ITIMER_REAL, &val, NULL);

    // 不让进程结束
    while(1) {
        sleep(10);
    }

    return 0;
}
```

### 进程通信

#### 管道

匿名管道

* 没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中
* 生命周期随着进程创建而建立，随着进程终止而消失
* 匿名管道是只能用于存在父子关系的进程间通信**

命名管道

* 在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信

管道怎么实现的？内核环形缓冲区

优点:简单

缺点

* 通信方式效率低，不适合进程间频繁地交换数据
* 数据是无格式的流且大小受限
* 通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道

#### 消息队列

实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型

优点

* 可以频繁通信了
* 可以独立于读写进程存在，避免了 FIFO 中同步管道打开和关闭可能产生的困难
* 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法
* 读进程可以根据消息消息类型有选择的接受消息，而不是像 FIFO 那样默认接受

缺点

* 通信不及时，每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。
* 消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。

消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系，消息队列会一直存在

#### 共享内存

共享内存原理

* 拿出一块虚拟地址空间来，映射到相同的物理内存中

* 解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，它直接分配一个共享空间，每个进程都可以直接访问

* 带来新的问题，多进程竞争同个共享资源会造成数据的错乱

    * 信号量
    * 条件变量 + 锁

    

共享内存和内存映射的区别

		1. 共享内存可以直接创建，内存映射需要磁盘文件（匿名映射除外）
		2. 共享内存效率更高
		3. 内存
  共享内存，所有的进程操作的是同一块共享内存。
  内存映射，每个进程在自己的虚拟地址空间中有一个独立的内存。
		4. 数据安全
  进程突然退出时，共享内存还存在，内存映射区消失
  运行进程的电脑死机，宕机时。在共享内存中的数据会消失。内存映射区的数据 ，由于磁盘文件中的数据还在，所以内存映射区的数据还存在。
		5. 生命周期
  内存映射区：进程退出，内存映射区销毁
  共享内存：进程退出，共享内存还在，标记删除（所有的关联的进程数为0），或者关机
  如果一个进程退出，会自动和共享内存进行取消关联。



内存通过什么来管理，有那些 API？

* 创建共享内存 shmget
* 共享内存映射 shmat
* 解除共享内存映射 shmdt
* 共享内存控制 shmctl

#### 信号

对于异常情况下的工作模式，就需要用「信号」的方式来通知进程
异步通信机制

进程有三种方式响应信号 

1. 执行默认操作
2. 捕捉信号

3. 忽略信号

有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SIGSTOP，这是为了方便我们能在任何时候结束或停止某个进程。
Ctrl+C 产生 `SIGINT`信号表示终止该进程
Ctrl+Z产生`SIGTSTP`信号，表示停止该进程但还没结束

#### Socket

不同主机的进程间通信

* 基于 TCP 协议的通信方式：socket 类型是 AF_INET 和 SOCK_STREAM；
* 基于 UDP 协议的通信方式：socket 类型是 AF_INET 和 SOCK_DGRAM；

本地进程间通信方式：

* 本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM
* 本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM
*  另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket
    实现效率比 IPv4，IPv6 大很多
* 不需要绑定 IP地址和端口，而是绑定一个本地文件



### 进程调度

#### 进程状态

在上面，我们知道了进程有着「运行 - 暂停 - 运行」的活动规律。一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。

它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。

所以，**在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。**

![进程的三种基本状态](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/7-%E8%BF%9B%E7%A8%8B%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81.jpg)

上图中各个状态的意义：

* 运行状态（*Running*）：该时刻进程占用 CPU；
* 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停止运行；
* 阻塞状态（*Blocked*）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

当然，进程还有另外两个基本状态：

* 创建状态（*new*）：进程正在被创建时的状态；
* 结束状态（*Exit*）：进程正在从系统中消失时的状态；

于是，一个完整的进程状态的变迁如下图：

![进程五种状态的变迁](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/8-%E8%BF%9B%E7%A8%8B%E4%BA%94%E4%B8%AA%E7%8A%B6%E6%80%81.jpg)

再来详细说明一下进程的状态变迁：

* *NULL -> 创建状态*：一个新进程被创建时的第一个状态；
* *创建状态 -> 就绪状态*：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；
* *就绪态 -> 运行状态*：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；
* *运行状态 -> 结束状态*：当进程已经运行完成或出错时，会被操作系统作结束状态处理；
* *运行状态 -> 就绪状态*：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；
* *运行状态 -> 阻塞状态*：当进程请求某个事件且必须等待时，例如请求 I/O 事件；
* *阻塞状态 -> 就绪状态*：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；

如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。

所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。

![虚拟内存管理-换入换出](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/9-%E6%8D%A2%E5%85%A5%E6%8D%A2%E5%87%BA.jpg)

那么，就需要一个新的状态，来**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。

另外，挂起状态可以分为两种：

* 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
* 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

这两种挂起状态加上前面的五种状态，就变成了七种状态变迁（留给我的颜色不多了），见如下图：

![七种状态变迁](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/10-%E8%BF%9B%E7%A8%8B%E4%B8%83%E4%B8%AD%E7%8A%B6%E6%80%81.jpg)

导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：

* 通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。
* 用户希望挂起一个程序的执行，比如在 Linux 中用 `Ctrl+Z` 挂起进程；

#### 什么时候发生调度？

1. 当前运行的进程运行结束。
2. 当前运行的进程由于某种原因阻塞。
3. 执行完系统调用等系统程序后返回用户进程。
4. 在使用抢占调度的系统中，具有更高优先级的进程就绪时。
5. 分时系统中，分给当前进程的时间片用完。

#### 不能进行调度的情况？

1. 在中断处理程序执行时。
2. 在操作系统的内核程序临界区内。
3. 其它需要完全屏蔽中断的原子操作过程中。

#### 非抢占式调度和抢占式调度区别？

如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：

* **非抢占式调度算法**挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。
* **抢占式调度算法**挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生**时钟中断**，以便把 CPU 控制返回给调度程序进行调度，也就是常说的**时间片机制**。

#### 调度算法考虑哪些原则？

* **CPU 利用率**：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；
* **系统吞吐量**：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
* **周转时间**：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；
* **等待时间**：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；
* **响应时间**：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。
* 确保每个工作获得一定比例的 CPU 时间（比例份额调度的特殊要求）

#### 单核CPU 常见进程调度算法有哪些？特点、优缺点、适用情况？

**先来先服务调度算法**

最简单的一个调度算法，就是非抢占式的**先来先服务（First Come First Severd, FCFS）算法**了。

![FCFS 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/24-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.jpg)

顾名思义，先来后到，**每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。**

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。

FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。

**最短作业优先调度算法**

**最短作业优先（Shortest Job First, SJF）调度算法**同样也是顾名思义，它会**优先选择运行时间最短的进程来运行**，这有助于提高系统的吞吐量。

![SJF 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/25-%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E7%AE%97%E6%B3%95.jpg)

这显然对长作业不利，很容易造成一种极端现象。

比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。

**高响应比优先调度算法**

前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。

那么，**高响应比优先 （Highest Response Ratio Next, HRRN）调度算法**主要是权衡了短作业和长作业。

**每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**，「响应比优先级」的计算公式：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg)

从上面的公式，可以发现：

* 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
* 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；

**时间片轮转调度算法**

最古老、最简单、最公平且使用最广的算法就是**时间片轮转（Round Robin, RR）调度算法**。

![RR 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/27-%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%AF%A2.jpg)

**每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。**

* 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；
* 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

另外，时间片的长度就是一个很关键的点：

* 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
* 如果设得太长又可能引起对短作业进程的响应时间变长。将

通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。

**最高优先级调度算法**

前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。

但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能**从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法**。

进程的优先级可以分为，静态优先级或动态优先级：

* 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
* 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

* 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
* 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行。

#### 比例份额调度算法

**基本概念：票数代表份额**

* 每个进程持有一些彩票号，调度程序每一次调度时，进行抽奖，持有开奖号数的进程被调度
* 利用了随机性，可以避免很多最差的情况

**彩票机制**

* 彩票货币：每个用户可以有自己的货币，最后再转换成调度程序的货币
* 彩票转让：进程可以临时将自己的彩票交给另一个进程
* 彩票膨胀：一个进程可以临时提升或降低彩票数量。只有进程相互信任的环境才有意义。

**步长调度**

* 每个工作都有步长，步长等于一个大数除以它的票数
* 每个进程都有行程值，每次调度完一个进程后，行程值增加它的步长
* 每次调度选择拥有最小行程值的进程
* 与彩票机制调度不同的是，由于彩票机制使用了随机性，所以可能无法提供正确的比例，特别是在短时间内发生的调度行为，而步长调度则是能够确保这种比例
* 而步长调度的缺点则是，在新进程加入时，它的行程值为0，会使得它长时间独占CPU

**问题**
如何分配票数？这个问题非常难解决，因此比例份额调度只有在容易确定份额的场景下才适用。

---

**Linux完全公平调度（CFS）**

**基本操作**
尽管大多数调度程序都是基于固定时间片的概念，但 CFS 的操作有所不同。它的目标很简单：**在所有竞争的进程之间平均分配 CPU。它通过称为虚拟运行时（vruntime）的基于计数的简单技术来实现。**
在每个进程运行时，它将积累 vruntime。在最基本的情况下，每个进程的虚拟运行时以相同的速率增长，与物理（实时）时间成比例。当发生调度决策时，CFS 将选择运行 vruntime最低的进程。
这就引出了一个问题：调度程序应该何时停止当前正在运行的进程，然后运行下一个进程？这里的压力很明显：如果CFS切换得太频繁，公平性就会增加，因为 CFS 将确保每个进程即使在很小的时间窗口内也能获得其 CPU 的份额，但是会以性能为代价（上下文切换过多）；如果CFS切换的频率较低，则性能会提高（上下文切换减少），但会以近期的公平为代价。CFS 通过各种控制参数来管理这种压力。

**调度延迟（sched_latency）**

 CFS 使用此值来确定在考虑切换之前一个进程应运行多长时间（以动态方式有效地确定其时间段）。典型的调度延迟时间值为48（毫秒）。 CFS将该值除以CPU上正在运行的进程数（n）来确定一个进程的时间片，从而确保在这段时间内 CFS 将完全公平。
例如，如果正在运行 n = 4 个进程，则 CFS 将调度延迟时间的值除以 n，得出每个进程的时间片为12 ms。然后，CFS 调度第一个任务并运行它，直到它使用了12毫秒的（虚拟）运行时为止，然后检查是否有一个具有较低 vruntime 的任务要运行。在这种情况下，CFS 将切换到其他三个任务之一，依此类推。下图显示了一个示例，其中四个任务（A，B，C，D）以这种方式分别运行两个时间片。然后，其中两个（C，D）完成，仅剩下两个，然后以循环方式分别运行24 ms。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917231054521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0luZ3N1aWZvbg==,size_16,color_FFFFFF,t_70#pic_center)

但是，如果运行的进程“太多”怎么办？那会不会导致时间片太小，从而导致上下文切换过多？

**最小粒度**

为了解决此问题，CFS 添加了另一个参数最小粒度，通常设置为6 ms之类的值。CFS永远不会将时间片设置小于该值，从而确保在调度开销方面不会花费太多时间。
例如，如果有十个进程在运行，我们的原始计算将调度的延迟除以十来确定时间片（结果：4.8毫秒）。但是，由于最小粒度，CFS会将每个进程的时间片设置为6ms。尽管CFS在48毫秒的目标调度延迟（调度延迟）上并不能（完全）公平，但在达到较高CPU效率的同时，它还是很接近的。
注意，CFS利用了周期性的计时中断，这意味着它只能以固定的时间间隔做出决定。该中断频繁关闭（例如，每1毫秒一次），使CFS有机会唤醒并确定当前任务是否已运行结束。如果任务的时间片不是计时中断间隔的完美倍数，则没问题； CFS精确跟踪vruntime，这意味着从长远来看，它将最终接近理想的CPU共享。

**加权（精细度）**
CFS还可以控制进程优先级，从而使用户或管理员可以为某些进程分配更高的 CPU 份额。它不使用票而是通过经典的UNIX机制（称为进程的nice级别）来完成的。可以将一个进程的nice参数设置为-20到+19之间的任意值，默认值为0。正的nice值表示优先级较低，而负的值表示优先级较高。
CFS将每个进程的nice值映射到权重，如下所示：

```
static const int prio_to_weight[40] = {
 /* -20 */ 88761, 71755, 56483, 46273, 36291,
 /* -15 */ 29154, 23254, 18705, 14949, 11916,
 /* -10 */ 9548, 7620, 6100, 4904, 3906,
 /* -5 */  3121, 2501, 1991, 1586, 1277,
 /* 0 */   1024, 820, 655, 526, 423,
 /* 5 */   335, 272, 215, 172, 137,
 /* 10 */  110, 87, 70, 56, 45,
 /* 15 */  36, 29, 23, 18, 15,
};
```

这些权重使我们能够计算每个进程的有效时间片（就像我们之前所做的一样），但是现在考虑了它们的优先级差异。这样做的公式如下：$\frac{weight_k}{\sum\limits^{n-1}_{i=0}weight_i}*sched\_latency$

让我们看一个例子，看看它是如何工作的。假设有两个任务，A和B。A，因为它是我们最宝贵的工作，被赋予了更高的优先级，所以分配给它的nice值-5；B，因为我们讨厌它，所以它具有默认优先级（nice值等于0）。这意味着 $weight_A$ 为3121，而$weight_B$ 为1024。然后，计算每个任务的时间片，A的时间片约为调度延迟的 $\frac{3}{4} $ （因此为36毫秒），而B的时间片约为$\frac{1}{4} $（因此为12毫秒）。
除了概括时间片计算之外，还必须调整 CFS 计算 vruntime 的方式。这是新的公式，它采用进程 $i $累计的实际运行时间（$runtime_i$），并按进程的权重进行反比例缩放。在我们的运行示例中，A的 vruntime 将以B的速度的三分之一累积。$vruntime_i=vruntime_i+\frac{weight_0}{weight_i}*runtime_i$ 上面的权重表的构造的一个明智的方面是，当nice值的差异恒定时，该表保留CPU比例比率。例如，如果进程A的nice值为5（不是-5），而进程B的nice值为10（不是0），则CFS将以与以前完全相同的方式调度它们。

**使用红黑树**
如上所述，CFS的一个主要重点是效率。对于调度程序而言，效率有很多方面，但是其中一个方面是如此简单：当调度程序必须找到要运行的下一个任务时，它应该尽快完成。像列表这样的简单数据结构无法扩展：现代系统有时由数千个进程组成，因此每隔几毫秒搜索一个长列表是很浪费的。
CFS通过将进程保存在红黑树中来解决此问题。红黑树是许多平衡树中的一种。与简单的二叉树（在最坏情况下的插入操作性能可能退化为类似链表的性能）相比，平衡树做了一些额外的工作来保持较低的深度，从而确保操作在时间上是对数级别的（而不是线性的）。
**CFS不会将所有进程都保留在此结构中，而是仅将运行（或可运行）的进程保留在其中。如果某个进程进入睡眠状态（例如，等待I / O完成，或者等待网络数据包到达），则将其从树中删除并跟踪其他位置。**
让我们看一个例子。假设有十个任务，并且它们具有以下vruntime值：1、5、9、10、14、18、17、21、22和24。如果我们将这些任务保留在有序列表中，查找下一个要运行的任务很简单：只需删除第一个元素。但是，当将该任务放回列表中时（按顺序），我们要扫描列表，寻找正确的位置将其插入，这是一个O（n）的操作。任何查找的效率也很低，平均也要花费线性时间。
在红黑树中保持相同的值可以使大多数操作更高效，如图所示。进程按 vruntime 在树中排序，并且大多数操作（例如插入和删除）在时间上都是对数的，即O（log n）。当n上千时，对数的效率明显高于线性的效率。

![img](https://img-blog.csdnimg.cn/20200917235919529.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0luZ3N1aWZvbg==,size_16,color_FFFFFF,t_70#pic_center)

**处理I / O和睡眠进程**
选择最低 vruntime 的进程来运行导致的一个问题是长期处于休眠状态的任务。想象一下两个进程，A 和 B，其中一个（A）连续运行，另一个（B）长时间睡眠（例如10秒）。当B醒来时，其 vruntime 将比A的运行时间晚10秒，因此（如果我们不小心的话），B现在会在接下来的10秒钟内独占CPU，使A饥饿。
CFS 通过在任务唤醒时更改其 vruntime 来处理这种情况。**具体来说，CFS 将该任务的 vruntime 设置为在树中找到的最小值（请记住，该树仅包含正在运行的任务）。这样，CFS避免了饥饿，但并非没有代价：短时间内频繁睡眠的任务经常无法获得应有的 CPU 份额。**

**CFS其他有趣的功能**
CFS具有许多其他功能，它包括多种启发式方法，可以提高缓存性能，具有有效处理多CPU的策略，可以跨大组进程进行调度（而不是将每个进程视为一个独立的实体），以及许多其他有趣的功能。

**总结**
我们介绍了比例分配调度的概念，并简要讨论了三种方法：彩票调度，步长调度和Linux的完全公平调度（CFS）。彩票调度巧妙地利用随机性来实现比例分配。步长调度非常具有确定性。 CFS是本章中讨论的唯一“真正的”调度程序，有点像带有动态时间片的加权循环调度，但是可以在负载下扩展和运行良好。据说，它是当今最广泛使用的公平份额调度程序。
没有调度程序是万能的灵丹妙药，公平份额的调度程序也有很多问题。
一个问题是这种方法不能与I / O很好地融合在一起；如上所述，偶尔执行I / O的任务可能无法公平得到CPU。另一个问题是，它们没有解决票或优先级分配的难题，即如何知道应该分配浏览器程序多少票，或者如何设置文本编辑器的nice值？其他通用调度程序（例如前面讨论的MLFQ和其他类似的Linux调度程序）会自动处理这些问题，因此可能更易于部署。
好消息是，在许多领域中，这些问题并不是主要问题，并且比例份额调度程序可发挥巨大作用。例如，在虚拟数据中心（或云）中，你可能希望将四分之一的CPU周期分配给Windows VM，其余的分配给基本的Linux安装，比例份额可以变得简单而有效。这个想法也可以扩展到其他资源。

#### 多级反馈队列调度

**多级反馈队列调度算法**（无先验经验）

**多级反馈队列（Multilevel Feedback Queue）调度算法**是「时间片轮转算法」和「最高优先级算法」的综合和发展。

顾名思义：

* 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
* 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

![多级反馈队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/28-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97.jpg)

来看看，它是如何工作的：

* 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
* 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
* 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**

#### 多处理器调度？

**单队列**

![img](https://pic4.zhimg.com/v2-f424f5893cd3bbdd49ebb77c8c70c3bf_b.jpg)

这种形式不需要在单处理器的框架下做太多改动，**同样的是维护一个进程的全局就绪队列，为所有 CPU 共享。运行在 CPU 上的调度程序从这个队列中挑选合适的进程执行。**

**特点**：

* 实现较简单，对所有的 CPU 来说很公平。
* 这个队列是全局共享的，所以当一个 CPU 挑选进程时需要加锁，不然多个 CPU 就可能选取同一个进程。但是锁机制不可避免带来额外的开销使得性能降低，可扩展性降低。
* 处理器亲和性(Processor Affinity)不容易实现，处理器亲和性是系统提供给用户的一种选择，用户可以指定特定的处理器来执行进程。
* 每个处理器都有自己的缓存，处理器亲和性不好，一个进程可能在多个处理器之间来回运行，使得处理器的缓存无效，所以缓存亲和性也不好，性能较为低下。

**多队列**

![img](https://pic4.zhimg.com/v2-af9ad1b1877b020d9412a56a0ff72877_b.jpg)

如上图所示：**每个 CPU 都有自己单独的调度队列**。每个 CPU 只在自己本地的队列中挑选合适的进程，速度很快。

**队列之间的调度相互独立**，可不再使用锁机制，可扩展性增强，比如每个队列可使用不同的调度算法。

**所有的任务工作都能在固定的 CPU 上执行，能够很好的利用缓存数据**。

**但是也有明显缺点：各个 CPU 的负载不均衡**，从上图就可以看出 CPU2 负载较大，而 CPU3 负载较小

**解决负载均衡的办法叫做迁移(Migration)，从繁忙 CPU 的队列中迁移一些进程到空闲 CPU 中去**。

#### 谈谈优先级反转以及解决思路？

**什么是优先级反转**
优先级反转是指使用信号量时，出现的一种不合理的反常现象，既是一个 高优先级任务 试图通过信号量机制访问某个共享资源时，哎，发现这个资源已经被低优先级任务占有。

人家抢先了就只能等呗，但是这就导致了低优先级任务 阻塞高优先级任务的现象，导致 高优先级任务 被 低优先级任务 阻塞，影响了 高优先级任务 的实时性。

最坏的情况下在 高优先级任务 等待低优先级任务的时候，出现一个中优先级任务，中优先级任务卡住了低优先级任务，却在被 高优先级任务 卡住，这就出现了类似死锁的情况发生。

系统运行对时间要求非常严格，如果因为某些问题导致系统时间延迟有误差，可能会导致比较严重的问题，这种情况在实时系统中会更严重。

![图片](https://mmbiz.qpic.cn/mmbiz_png/Qof5hj3zMPe0ZReyzKfI0yicdicFjowJDcxMswOF30AxPZnC2MoEWial34GMia8HnNmX2PaBr5A0J4SemxuZicWiaPNA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

A和C共享一个资源，但是在运行过程中，在某一个时刻，C占有资源的时候，被高于它优先级的进程B抢占了，这时候B就处于一个有利位置，一直会有CPU运行，如果有其他进程优先级高于C的，也会能拿到CPU运行。

这就出现了一个奇怪的现象，**低优先级的进程抢占了高优先级的进程，如果A是特斯拉的刹车进程的话，我相信故障就此发生。**

**如何解决优先级翻转的问题呢？**

提升C的优先级，让C的优先级高于B，就不会存在持有锁的情况下被抢占。

但是C的优先级提升到多少合适呢？

假设共享资源R，有5个任务会申请它，我们需要做的是，持有R资源的任务的优先级是这5个任务中最高的，这就叫**优先级提升**。

**解决方法 1 ：优先权极限**
在优先权极限方案中，系统把每一个临界资源与1个极限优先权相联系。这个极限优先权等于系统此时最高优先权加1。当1个任务进入临界区时，系统便把这个极限 优先权传递给这个任务，使得这个任务的优先权最高；
当这个任务退出临界区后，系统立即把它的优先权恢复正常，从而保证系统不会出现优先权反转的情况。如上例中，当 低优先权任务 进入临界区时，立即把它的优先权升高到极限优先权，保证低优先权任务 此时能尽快退出临界区，进而释放其占有的信号量。当 高优先级任务 执行的时候就不会出现其等待 低优先级任务 释放信号量而被阻塞的情况，从而保证不会出现上面所说的优先级反转。采用这种方案的另一个有利之处，是仅仅通过改变某个临界资源的优先级就可以使多个任务共享这个临界资源

**解决方法 2 ：优先级继承**
在优先级继承方案中，大致原理是让低优先级线程在获得同步资源的时候(如果有高优先级的线程也需要使用该同步资源时)，临时提升其优先级。以前其能更快的执行并释放同步资源。释放同步资源后再恢复其原来的优先级。

当 高优先级任务 想要进入临界区时，由于 低优先级任务 占有这个临界资源的信号量，导致 高优先级任务 被阻塞。这时候，系统把 低优先级任务 的优先权升到 高优先级任务 的优先级，此时优先级处于 低优先级任务 和 高优先级任务 之间的任务 中优先级任务，即使处于就绪状态也不可以被调度执行，因为此时低优先级任务 的优先权已经高于 中优先级任务，所以低优先级任务 此时被调度执行。当 低优先级任务 释放 高优先级任务 需要的信号量时，系统立即把 低优先级任务 的优先权降到原 来的高度，来保证task1和task2正常有序执行。
于是只有中优先级受伤的世界出现了

#### Linux 如何调度线程 （CPU 如何选择线程）

在 Linux 内核中，进程和线程都是用 `task_struct` 结构体表示的，**区别在于线程的 task_struct 结构体里部分资源是共享了进程已创建的资源，比如内存地址空间、代码段、文件描述符等，所以 Linux 中的线程也被称为轻量级进程，因为线程的 task_struct 相比进程的 task_struct 承载的 资源比较少，因此以「轻」得名。**

一般来说，没有创建线程的进程，是只有单个执行流，它被称为是主线程。如果想让进程处理更多的事情，可以创建多个线程分别去处理，但不管怎么样，它们对应到内核里都是 `task_struct`。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/%E4%BB%BB%E5%8A%A1.png)

所以，Linux 内核里的调度器，调度的对象就是 `task_struct`，接下来我们就把这个数据结构统称为**任务**。

在 Linux 系统中，**根据任务的优先级以及响应要求**，主要分为两种，其中优先级的数值越小，优先级越高：

* 实时任务，对系统的响应时间要求很高，也就是要尽可能快的执行实时任务，优先级在 `0~99` 范围内的就算实时任务；
* 普通任务，响应时间没有很高的要求，优先级在 `100~139` 范围内都是普通任务级别；

##### 调度类

由于任务有优先级之分，Linux 系统为了保障高优先级的任务能够尽可能早的被执行，于是分为了这几种调度类，如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/%E8%B0%83%E5%BA%A6%E7%B1%BB.png)

Deadline 和 Realtime 这两个调度类，都是应用于实时任务的，这两个调度类的调度策略合起来共有这三种，它们的作用如下：

* *SCHED_DEADLINE*：是按照 deadline 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度；
* *SCHED_FIFO*：对于相同优先级的任务，按先来先服务的原则，但是优先级更高的任务，可以抢占低优先级的任务，也就是优先级高的可以「插队」；
* *SCHED_RR*：对于相同优先级的任务，轮流着运行，每个任务都有一定的时间片，当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是高优先级的任务依然可以抢占低优先级的任务；

而 Fair 调度类是应用于普通任务，都是由 CFS 调度器管理的，分为两种调度策略：

* *SCHED_NORMAL*：普通任务使用的调度策略；
* *SCHED_BATCH*：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。

##### 完全公平调度

我们平日里遇到的基本都是普通任务，对于普通任务来说，公平性最重要，在 Linux 里面，实现了一个基于 CFS 的调度算法，也就是**完全公平调度（Completely Fair Scheduling）**。

**这个算法的理念是想让分配给每个任务的 CPU 时间是一样，于是它为每个任务安排一个虚拟运行时间 vruntime，如果一个任务在运行，其运行的越久，该任务的 vruntime 自然就会越大，而没有被运行的任务，vruntime 是不会变化的。**

那么，**在 CFS 算法调度的时候，会优先选择 vruntime 少的任务**，以保证每个任务的公平性。

这就好比，让你把一桶的奶茶平均分到 10 杯奶茶杯里，你看着哪杯奶茶少，就多倒一些；哪个多了，就先不倒，这样经过多轮操作，虽然不能保证每杯奶茶完全一样多，但至少是公平的。

当然，上面提到的例子没有考虑到优先级的问题，虽然是普通任务，但是普通任务之间还是有优先级区分的，所以在计算虚拟运行时间 vruntime 还要考虑普通任务的**权重值**，注意权重值并不是优先级的值，内核中会有一个 nice 级别与权重值的转换表，nice 级别越低的权重值就越大，至于 nice 值是什么，我们后面会提到。 于是就有了以下这个公式：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/vruntime.png)

你可以不用管 NICE_0_LOAD 是什么，你就认为它是一个常量**，那么在「同样的实际运行时间」里，高权重任务的 vruntime 比低权重任务的 vruntime 少**，你可能会奇怪为什么是少的？你还记得 CFS 调度吗，它是会优先选择 vruntime 少的任务进行调度，所以高权重的任务就会被优先调度了，于是高权重的获得的实际运行时间自然就多了。

##### CPU 运行队列

一个系统通常都会运行着很多任务，多任务的数量基本都是远超 CPU 核心数量，因此这时候就需要**排队**。

事实上，每个 CPU 都有自己的**运行队列（Run Queue, rq）**，用于描述在此 CPU 上所运行的所有进程，其队列包含三个运行队列，Deadline 运行队列 dl_rq、实时任务运行队列 rt_rq 和 CFS 运行队列 cfs_rq，其中 cfs_rq 是用红黑树来描述的，按 vruntime 大小来排序的，最左侧的叶子节点，就是下次会被调度的任务。

PS：下图中的 csf_rq 应该是 `cfs_rq`，由于找不到原图了，我偷个懒，我就不重新画了，嘻嘻。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/CPU%E9%98%9F%E5%88%97.png)

这几种调度类是有优先级的，优先级如下：Deadline > Realtime > Fair，这意味着 Linux 选择下一个任务执行的时候，会按照此优先级顺序进行选择，也就是说先从 `dl_rq` 里选择任务，然后从 `rt_rq` 里选择任务，最后从 `cfs_rq` 里选择任务。因此，**实时任务总是会比普通任务优先被执行**。

##### 调整优先级

如果我们启动任务的时候，没有特意去指定优先级的话，默认情况下都是普通任务，普通任务的调度类是 Fair，由 CFS 调度器来进行管理。CFS 调度器的目的是实现任务运行的公平性，也就是保障每个任务的运行的时间是差不多的。

如果你想让某个普通任务有更多的执行时间，可以调整任务的 `nice` 值，从而让优先级高一些的任务执行更多时间。nice 的值能设置的范围是 `-20～19`， 值越低，表明优先级越高，因此 -20 是最高优先级，19 则是最低优先级，默认优先级是 0。

是不是觉得 nice 值的范围很诡异？事实上，**nice 值并不是表示优先级，而是表示优先级的修正数值**，它与优先级（priority）的关系是这样的：priority(new) = priority(old) + nice。内核中，priority 的范围是 0~139，值越低，优先级越高，其中前面的 0~99 范围是提供给实时任务使用的，而 nice 值是映射到 100~139，这个范围是提供给普通任务用的，因此 nice 值调整的是普通任务的优先级。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/%E4%BC%98%E5%85%88%E7%BA%A7.png)

在前面我们提到了，权重值与 nice 值的关系的，**nice 值越低，权重值就越大，计算出来的 vruntime 就会越少**，由于 CFS 算法调度的时候，就会优先选择 vruntime 少的任务进行执行，所以 nice 值越低，任务的优先级就越高。

我们可以在启动任务的时候，可以指定 nice 的值，比如将 mysqld 以 -3 优先级：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/nice.png)

如果想修改已经运行中的任务的优先级，则可以使用 `renice` 来调整 nice 值：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/renice.png)

nice 调整的是普通任务的优先级，所以不管怎么缩小 nice 值，任务永远都是普通任务，如果某些任务要求实时性比较高，那么你可以考虑改变任务的优先级以及调度策略，使得它变成实时任务，比如：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/chrt.png)

另外还可以通过可以通过top命令来查看优先级，NI那一列。

并且也可以通过 top 来 改变进程的优先级：top命令，输入r，然后根据提示输入进程ID，再输入优先级数值。

在嵌入式Linux系统中，大多都是跑一个核心的业务，在数据吞吐量大的时候，会大量占用CPU，导致数据处理不过来，常规办法是优化程序或者更换更高性能的平台来解决，但是如果程序已经优化到极限和平台无法更换的情况下，可以通过提高业务进程的优先级来提高业务数据的吞吐量,例如：在做网络数据分析的时候该方法非常管用，没有提高优先级时，数据吞吐量大概为800Mbps，再往上就开始处理不过来了，直到应用层buffer满了导致数据丢失，将进程提高到最高优先级，数据吞吐量可以提高到接近900Mbps，效果相当明显。

### 进程上下文

#### 谈一下 系统调用、CPU 上下文切换、进程上下文切换、线程上下文切换、中断上下文切换

**CPU上下文切换**
进程在竞争 CPU 的时候并没有真正运行，为什么还会导致系统的负载升高呢？CPU 上下文切换就是罪魁祸首。

我们都知道，Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。

而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要**系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）**。

**CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。**

知道了什么是 CPU 上下文，我想你也很容易理解 CPU 上下文切换。CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

操作系统管理的这些“任务”到底是什么呢？

**所以，根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。**

**进程上下文切换**
Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中，CPU 特权等级的 Ring 0 和 Ring 3。

内核空间（Ring 0）具有最高权限，可以直接访问所有资源；

用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210630215953751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01pbmRfcHJvZ3JhbW1vbmtleQ==,size_16,color_FFFFFF,t_70#pic_center)

那么，系统调用的过程有没有发生 CPU 上下文的切换呢？答案自然是肯定的。

CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。

而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，**一次系统调用的过程，其实是发生了两次 CPU 上下文切换。**

**那么，进程上下文切换跟系统调用又有什么区别呢？**

* 进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，**进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态**。因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。
* 进程上下文切换，是指从一个进程切换到另一个进程运行。而系统调用过程中一直是同一个进程在运行。

**线程上下文切换**
线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。

说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。

这么一来，线程的上下文切换其实就可以分为两种情况：

* 第一种， 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
* 第二种，前后两个线程属于同一个进程。**此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。**

到这里你应该也发现了，虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。

**中断上下文切换**
除了前面两种上下文切换，还有一个场景也会切换 CPU 上下文，那就是中断。

为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。**中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。**

对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。

#### 进程在哪些场景会进行上下文切换？

* 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；
* 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；
* 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；
* 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
* 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；

#### 进程上下文切换做了哪些事？流程是怎么样的？

进程切换的视图：

![image.png](https://s2.loli.net/2022/10/06/QydSZ6VWICzGYL2.png)

 **关键点：**

1. 发生中断时的保存现场，将发生中断时的所有通用寄存器保存到进程的内核栈，使用struct pt_regs结构。
2. 地址空间切换将进程自己的页全局目录的基地址 pgd 保存在ttbr0_le1中，用于mmu 的页表遍历的起始点。
3. 硬件上下文切换的时候，将此时的调用保存寄存器和pc, sp保存到struct cpu_context结构中。做好了这几个保存工作，当进程再次被调度回来的时候，通过cpu_context中保存的pc回到了cpu_switch_to的下一条指令继续执行，而由于cpu_context中保存的sp导致当前进程回到自己的内核栈，经过一系列的内核栈的出栈处理，最后将原来保存在pt_regs中的通用寄存器的值恢复到了通用寄存器，这样进程回到用户空间就可以继续沿着被中断打断的下一条指令开始执行，用户栈也回到了被打断之前的位置，而进程访问的指令数据做地址转化（VA到PA）也都是从自己的pgd开始进行，一切对用户来说就好像没有发生一样。

**总结；**

　　进程切换有两大步骤：地址空间切换和处理器状态切换（硬件上下文切换）。前者保证了进程回到用户空间之后能够访问到自己的指令和数据（其中包括减小tlb清空的ASID机制），后者保证了进程内核栈和执行流的切换，会将当前进程的硬件上下文保存在进程所管理的一块内存，然后将即将执行的进程的硬件上下文从内存中恢复到寄存器，有了这两步的切换过程保证了进程运行的有条不紊，当然切换的过程是在内核空间完成，这对于进程来说是透明的。

#### 上下文切换为什么资源消耗会比较高？消耗在什么地方？

**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：

![进程上下文切换](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/13-%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2.jpg)

大家需要注意，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。

### 进程控制

#### 进程控制结构？包含哪些信息？

在操作系统中，是用**进程控制块**（*process control block，PCB*）数据结构来描述进程的。**PCB 是进程存在的唯一标识**，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。

PCB 具体包含什么信息呢？

**进程描述信息：**

* 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
* 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

**进程控制和管理信息：**

* 进程当前状态，如 new、ready、running、waiting 或 blocked 等；
* 进程优先级：进程抢占 CPU 时的优先级；

**资源分配清单：**

* 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。

**CPU 相关信息：**

* CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

#### PCB 是如何组织？几种方式优缺点（要改）

通常是通过**链表**的方式进行组织，把具有**相同状态的进程链在一起，组成各种队列**。比如：

* 将所有处于就绪状态的进程链在一起，称为**就绪队列**；
* 把所有因等待某事件而处于等待状态的进程链在一起就组成各种**阻塞队列**；
* 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。

那么，就绪队列和阻塞队列链表的组织形式如下图：

![就绪队列和阻塞队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/12-PCB%E7%8A%B6%E6%80%81%E9%93%BE%E8%A1%A8%E7%BB%84%E7%BB%87.jpg)

除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。

一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。

#### 如何创建进程

操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。

创建进程的过程如下：

* 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；
* 为该进程分配运行时所必需的资源，比如内存资源；
* 将 PCB 插入到就绪队列，等待被调度运行；

#### 如何终止进程

进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 `kill` 掉）。

当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。

终止进程的过程如下：

* 查找需要终止的进程的 PCB；
* 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；
* 如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；
* 将该进程所拥有的全部资源都归还给操作系统；
* 将其从 PCB 所在队列中删除；

1、main函数的自然返回，return

2、调用exit函数，属于c的函数库

3、调用_exit函数，属于系统调用

4、调用abort函数，异常程序终止，同时发送SIGABRT信号给调用进程。

 5、接受能导致进程终止的信号：ctrl+c (^C)、SIGINT(SIGINT中断进程)

exit和_exit的区别

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-39-1.png)

#### 如何阻塞进程

当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。

阻塞进程的过程如下：

* 找到将要被阻塞进程标识号对应的 PCB；
* 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；
* 将该 PCB 插入到阻塞队列中去；

#### 如何唤醒进程

进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。

如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。

唤醒进程的过程如下：

* 在该事件的阻塞队列中找到相应进程的 PCB；
* 将其从阻塞队列中移出，并置其状态为就绪状态；
* 把该 PCB 插入到就绪队列中，等待调度程序调度；

进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。

#### Linux 系统如何管理进程？

每个进程在内核中都有一个进程控制块(PCB)来维护进程相关的信息,Linux内核的进程控制块是task_struct结构体.

task_struct是Linux内核的一种数据结构，它会被装载到RAM中并且包含着进程的信息。每个进程都把它的信息放在 task_struct 这个数据结构体，task_struct 包含了这些内容：

> 1. **标示符**： 描述本进程的唯一标识符，用来区别其他进程。
> 2. **状态** ：任务状态，退出代码，退出信号等。
> 3. **优先级** ：相对于其他进程的优先级。
> 4. **程序计数器**：程序中即将被执行的下一条指令的地址。
> 5. **内存指针**：包括程序代码和进程相关数据的指针，还有和其他进程共享的内存块的指针。
> 6. **上下文数据**：进程执行时处理器的寄存器中的数据。
> 7. **I/O状态信息**：包括显示的I/O请求,分配给进程的I/O设备和被进程使用的文件列表。
> 8. **记账信息**：可能包括处理器时间总和，使用的时钟数总和，时间限制，记账号等。

有关进程信息还有以下三点需要了解：

> 1. 保存进程信息的数据结构叫做 task_struct，可以在 include/linux/sched.h 中找到它；
> 2. 所有运行在系统中的进程都以 task_struct 链表的形式存在内核中；
> 3. 进程的信息可以通过 /proc 系统文件夹查看。要获取PID为400的进程信息，你需要查看 /proc/400 这个文件夹。大多数进程信息同样可以使用top和ps这些用户级工具来获取,例如：

![img](https:////upload-images.jianshu.io/upload_images/12535952-d04f7af40f9bce32.png?imageMogr2/auto-orient/strip|imageView2/2/w/680/format/webp)

#### fork 和 vfork 区别

**fork的基础知识：**

fork:创建一个和当前进程映像一样的进程可以通过fork( )系统调用：

```c++
#include <sys/types.h>

#include <unistd.h>

pid_t fork(void);
```

成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。

最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。

在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

**vfork的基础知识：**

在实现写时复制之前，Unix的设计者们就一直很关注在fork后立刻执行exec所造成的地址空间的浪费。BSD的开发者们在3.0的BSD系统中引入了vfork( )系统调用。

```c++
#include <sys/types.h>

#include <unistd.h>

pid_t vfork(void);
```

除了子进程必须要立刻执行一次对exec的系统调用，或者调用_exit( )退出，对vfork( )的成功调用所产生的结果和fork( )是一样的。vfork( )会挂起父进程直到子进程终止或者运行了一个新的可执行文件的映像。通过这样的方式，vfork( )避免了地址空间的按页复制。在这个过程中，父进程和子进程共享相同的地址空间和页表项。实际上vfork( )只完成了一件事：复制内部的内核数据结构。因此，子进程也就不能修改地址空间中的任何内存。

vfork( )是一个历史遗留产物，Linux本不应该实现它。需要注意的是，即使增加了写时复制，vfork( )也要比fork( )快，因为它没有进行页表项的复制。然而，写时复制的出现减少了对于替换fork( )争论。实际上，直到2.2.0内核，vfork( )只是一个封装过的fork( )。因为对vfork( )的需求要小于fork( )，所以vfork( )的这种实现方式是可行的。

**补充知识点：写时复制**

Linux采用了写时复制的方法，以减少fork时对父进程空间进程整体复制带来的开销。

写时复制是一种采取了惰性优化方法来避免复制时的系统开销。它的前提很简单：如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的。每个进程只要保存一个指向这个资源的指针就可以了。只要没有进程要去修改自己的“副本”，就存在着这样的幻觉：每个进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程。不过其中的复制对进程来说是透明的。这个进程就可以修改复制后的资源了，同时其他的进程仍然共享那份没有修改过的资源。所以这就是名称的由来：在写入时进行复制。

写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。

在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以**页为基础**进行的。所以，只要进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork( )调用结束后，父进程和子进程都相信它们有一个自己的地址空间，**但实际上它们共享父进程的原始页**，接下来这些页又可以被其他的父进程或子进程共享。

写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。如果有进程试图修改一个页，就会产生一个缺页中断。**内核处理缺页中断的方式就是对该页进行一次透明复制。这时会清除页面的COW属性，表示着它不再被共享**。

**现代的计算机系统结构中都在内存管理单元（MMU）提供了硬件级别的写时复制支持，所以实现是很容易的。**

在调用fork( )时，写时复制是有很大优势的。因为大量的fork之后都会跟着执行exec，那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间：如果子进程立刻执行一个新的二进制可执行文件的映像，它先前的地址空间就会被交换出去。写时复制可以对这种情况进行优化。

**fork和vfork的区别：**

1. fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段

2. fork( )的父子进程的执行次序不确定；**vfork( )保证子进程先运行**，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。

3. vfork( )保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。

4. 当需要改变共享数据段中变量的值，则拷贝父进程。

#### fork,wait,exec

父进程产生子进程使用fork拷贝出来一个父进程的副本，此时只拷贝了父进程的页表，两个进程都读同一块内存，当有进程写的时候使用写时拷贝机制分配内存，exec函数可以加载一个elf文件去替换父进程，从此父进程和子进程就可以运行不同的程序了。

fork从父进程返回子进程的pid，从子进程返回0.

调用了wait的父进程将会发生阻塞，直到有子进程状态改变,执行成功返回0，错误返回-1。

exec执行成功则子进程从新的程序开始运行，无返回值，执行失败返回-1

**请你来说一下fork函数**

参考回答：
Fork：创建一个和当前进程映像一样的进程可以通过fork( )系统调用：

```c
#include <sys/types.h>

#include <unistd.h>

pid_t fork(void);
```

成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。

最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。

在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

**请你来手写一下fork调用示例**

1、概念：
Fork：创建一个和当前进程映像一样的进程可以通过fork( )系统调用：

成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。

最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。

在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

2、fork实例

```c
int main(void)
{
pid_t pid;
signal(SIGCHLD, SIG_IGN);
printf("before fork pid:%d\n", getpid());
int abc = 10;
pid = fork();
if (pid == -1) {           //错误返回

perror("tile");
return -1;
}
if (pid > 0) {              //父进程空间

abc++;
printf("parent:pid:%d \n", getpid());
printf("abc:%d \n", abc);
sleep(20);
}
else if (pid == 0) {       //子进程空间
abc++;
printf("child:%d,parent: %d\n", getpid(), getppid());
printf("abc:%d", abc);
}
printf("fork after...\n");
 }
```

以Unix系统举例：

1. 进程的创建：fork()。新创建的子进程几乎但不完全与父进程相同。**子进程得到与父进程用户级虚拟地址空间相同的(但是独立的)一份副本，包括代码和数据段、堆、共享库以及用户栈**。**子进程还获得与父进程任何打开文件描述符相同的副本**，这就意味着当父进程调用 fork 时，子进程可以读写父进程中打开的任何文件。父进程和新创建的子进程之间最大的区别在于它们有不同的 PID。fork函数是有趣的（也常常令人迷惑）， 因为它只被调用一次，却会返回两次：一次是在调用进程（父进程）中，一次是在新创建的子进程中。在父进程中，fork 返回子进程的 PID。在子进程中，fork 返回 0。因为子进程的 PID 总是为非零，返回值就提供一个明 确的方法来分辨程序是在父进程还是在子进程中执行。

```C++
pid_t fork(void);
```

2. 回收子进程：当一个进程由于某种原因终止时，内核并不是立即把它从系统中清除。相反，进程被
 保持在一种已终止的状态中，直到被它的父进程回收（reaped）。当父进程回收已终止的子进程
    时，内核将子进程的退出状态传递给父进程，然后抛弃已终止的进程。一个进程可以通过调用
    waitpid 函数来等待它的子进程终止或者停止。

  ```C
pid_t waitpid(pid_t pid, int *statusp, int options);
  ```

3. 加载并运行程序：execve 函数在当前进程的上下文中加载并运行一个新程序。

  ```C
int execve(const char *filename, const char *argv[], const char *envp[]);
  ```

4. 进程终止：

  ```C
void exit(int status);
  ```

#### fork复制内部，为什么fork返回0？

[参考链接](https://juejin.cn/post/6909074860761169933)

fork是一个宏，内部关键指令就是0x80中断，会进入system_cal这个函数，然后有一个sys_cal_table。这个表就是一个系统调用函数表，存的都是函数指针，根据索引找到sys_fork这个函数，能找到这个函数就是因为由寄存器eax传过来个值2，索引为2的函数指针就是sys_fork。sys_fork实现调用了do_fork，do_Fork()里面有一个copy_process()。事实上fork就是实现了sys_fork。

**为什么子进程先运行：**

do_fork()第一步是调用copy_process函数来复制一个进程，并对相应的标志位等进行。设置如果copy_process调用成功的话，那么系统会有意让新开辟的进程运行，这是因为子进程一般都会马上调用exec()函数来执行其他的任务，这样就可以避免写是复制造成的开销，或者从另一个角度说，如果其首先执行父进程，而父进程在执行的过程中，可能会向地址空间中写入数据，那么这个时候，系统就会为子进程拷贝父进程原来的数据，而当子进程调用的时候，其紧接着执行拉exec()操作，那么此时，系统又会为子进程拷贝新的数据，这样的话，相比优先执行子程序，就进行了一次“多余”的拷贝。

[参考链接](https://www.zhihu.com/question/59296096)该连接中说在多核是可以同时执行的，单核的话不确定，但是cow来说确实应该子进程先执行。

我们可以通过fork返回的值来判断当前进程是子进程还是父进程。通俗的解释，可以这样看待：“其实就相当于链表，进程形成了链表，父进程的fork函数返回的值指向子进程的进程id, 因为子进程没有子进程，所以其fork函数返回的值为0.

作者：Napoleon
链接：<https://www.zhihu.com/question/59296096/answer/1707711827>
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

下面阐述两种先后顺序策略的考虑，和反映先后顺序的方法。

fork之后先调度父进程

fork之后，[父进程](https://www.zhihu.com/search?q=父进程&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1707711827})在CPU中正处于活跃状态，并且其内存管理信息也被置于硬件内存管理单元的TLB中。所以，先运行父进程将提高性能。

fork之后先调度子进程

考虑当fork产生的子进程立即执行exec时“写时复制”所发生的情况。此时，一方面父进程在fork之后继续修改数据页和栈页，另一方面内核要为子进程复制那些“将要修改”的页。由于[子进程](https://www.zhihu.com/search?q=子进程&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1707711827})一旦获得调度会立即执行exec，所以这一页复制动作纯属浪费，先调度子进程的决策更佳。如此一来，等到下次调度到父进程时，就无需复制[内存页](https://www.zhihu.com/search?q=内存页&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1707711827})了。

两种行为间的性能差异很小，对于大部分应用程序并无影响。

归因于操作系统具体实现、具体运行情况不同，调用fork()之后，系统先调度哪个进程（即调度其使用CPU），是无法确定的。

如果依赖这个不确定的结论，那么将可能因竞争条件而导致失败。由于此类问题的发生取决于内核根据系统当时的负载而做出的调度决定，所以往往难以发现。

如上述讨论，为了保证程序的健壮性，不应对fork之后执行父、子进程的特定顺序做任何假设。若确需保证某一特定执行顺序，则必须采用某种[同步技术](https://www.zhihu.com/search?q=同步技术&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1707711827})。

------

如果只是想看看当前系统具体是何状况，可以使用下面的程序。

```c
int
main(int argc, char *argv[])
{
    int numChildren, j;
    pid_t childPid;

    if (argc > 1 && strcmp(argv[1], "--help") == 0)
        usageErr("%s [num-children]\n", argv[0]);

    numChildren = (argc > 1) ? getInt(argv[1], GN_GT_0, "num-children") : 1;

    setbuf(stdout, NULL);

    for (j = 0; j < numChildren; j++) {
        switch (childPid = fork()) {
        case -1:
            errExit("fork");

        case 0:
            printf("%d child\n", j);
            _exit(EXIT_SUCCESS);

        default:
            printf("%d parent\n", j);
            wait(NULL);
            break;
        }
    }

    exit(EXIT_SUCCESS);
}
```

执行下面的命令，统计fork10000次的结果百分比。

```bash
./a.out 10000 | awk 'BEGIN { last = -1; } { if ($1 != last) { cat[$2]++; tot++; } last = $1; } END { print "All done"; for (k in cat)  printf "%-6s %6d %6.2f%%\n", k, cat[k], cat[k] / tot * 100; }'
```

经测试，在我的机器上，结果表明父进程先输出的情况占总数的99.98%。

建议看一下参考连接文章里的参考连接

还有这一篇 <https://www.cnblogs.com/sky-heaven/p/13073979.html> 如何验证（不要用 printf）

**调用fork()后，无法确定父、子进程间谁将率先访问CPU。**

* 在多处理器系统中，它们可能会同时各自访问一个CPU。
* 在单处理器系统中，fork()之后很可能总是先调度父进程（优化性能），但如果恰好父进程的CPU时间片到期了，则执行子进程。

要想保证按一特定顺序执行，必须采用相应的同步机制。

 参考：Linux/UNIX系统编程手册 24.4 fork()之后的竞争条件（Rece Condittion）

**铭记：不应当假设 fork 后父进程先运行还是子进程先运行**

你有没有想过，在多核机器上，父子进程可以同时执行，没有先后之分，你问的“先后顺序”这个问题可能是无意义的。

[Does the Linux scheduler prefer to run child process after fork()?](https://link.zhihu.com/?target=http%3A//stackoverflow.com/questions/23695915/does-the-linux-scheduler-prefer-to-run-child-process-after-fork)
[Does /proc/sys/kernel/sched_child_runs_first work?](https://link.zhihu.com/?target=http%3A//stackoverflow.com/questions/17391201/does-proc-sys-kernel-sched-child-runs-first-work/17393268%2317393268)

作者：陈硕
链接：<https://www.zhihu.com/question/59296096/answer/165362153>
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
